{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv\n",
        "!pip install ipython-sql"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0YHLgiKVyCi",
        "outputId": "f5ad4226-378c-4ec0-e1a4-98f8841c306e"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n",
            "Requirement already satisfied: ipython-sql in /usr/local/lib/python3.10/dist-packages (0.5.0)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from ipython-sql) (3.10.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-sql) (7.34.0)\n",
            "Requirement already satisfied: sqlalchemy>=2.0 in /usr/local/lib/python3.10/dist-packages (from ipython-sql) (2.0.31)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.10/dist-packages (from ipython-sql) (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ipython-sql) (1.16.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipython-sql) (0.2.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0->ipython-sql) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=2.0->ipython-sql) (3.0.3)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-sql) (67.7.2)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-sql) (0.19.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-sql) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-sql) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-sql) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-sql) (3.0.47)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-sql) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-sql) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-sql) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-sql) (4.9.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->ipython-sql) (0.2.13)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-sql) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-sql) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# config.py\n",
        "\n",
        "# the \"%%\" magic code below writes these code blocks to the ephemeral colab filesystem.\n",
        "# !!! NB THIS STOPS THE CELL CODE FROM BEING RUN IN COLAB ENVIRONMENT !!!\n",
        "%%writefile config.py\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()  # Load environment variables from .env file\n",
        "\n",
        "EODHD_API_KEY = os.getenv(\"EODHD_API_KEY\")\n",
        "SQL_USER = os.getenv(\"SQL_USER\")\n",
        "SQL_PASS =  os.getenv(\"SQL_PASS\")\n",
        "SQL_HOST = os.getenv(\"SQL_HOST\")\n",
        "\n",
        "# Dictionary with  UK/US government bond symbols as keys and with list of maturity classes and countries as values\n",
        "# *** I had subtantial issues as a result of the values in this dict being UPPER\n",
        "# CASE initially ***\n",
        "bond_symbols_dict = {\n",
        "    'UK1Y.GBOND': ['1y', 'uk'],\n",
        "    'UK2Y.GBOND': ['2y', 'uk'],\n",
        "    'UK3Y.GBOND': ['3y', 'uk'],\n",
        "    'UK5Y.GBOND': ['5y', 'uk'],\n",
        "    'UK10Y.GBOND': ['10y', 'uk'],\n",
        "    'UK30Y.GBOND': ['30y', 'uk'],\n",
        "    'US1Y.GBOND': ['1y', 'us'],\n",
        "    'US2Y.GBOND': ['2y', 'us'],\n",
        "    'US3Y.GBOND': ['3y', 'us'],\n",
        "    'US5Y.GBOND': ['5y', 'us'],\n",
        "    'US10Y.GBOND': ['10y', 'us'],\n",
        "    'US30Y.GBOND': ['30y', 'us'],\n",
        "    'DE1Y.GBOND': ['1y', 'de'],  # German 1-year bond\n",
        "    'DE2Y.GBOND': ['2y', 'de'],\n",
        "    'DE5Y.GBOND': ['5y', 'de'],\n",
        "    'DE10Y.GBOND': ['10y', 'de'],\n",
        "    'DE30Y.GBOND': ['30y', 'de'],\n",
        "}"
      ],
      "metadata": {
        "id": "HCvSbgv_14gc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3a1db8-63fe-4638-e464-8b0dc80b2b80"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting config.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BELOW temp config code block for credentials etc during initial development in this notebook\n",
        "\n",
        "# from google.colab import userdata\n",
        "\n",
        "# my_password = userdata.get('SQLPass')\n",
        "# my_user = userdata.get('SQLUser')\n",
        "# my_host = userdata.get('host')\n"
      ],
      "metadata": {
        "id": "Xa2i9CtTq5Ae"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JgmFIAEYying",
        "outputId": "6081bf3f-2f02-47fe-c6a3-bef31eb2f0bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting extract_transform.py\n"
          ]
        }
      ],
      "source": [
        "# extract_transform.py\n",
        "%%writefile extract_transform.py\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "from config import EODHD_API_KEY\n",
        "\n",
        "# from config import EODHD_API_KEY\n",
        "def get_eod_data(symbol, api_token):\n",
        "    \"\"\"Fetches EOD (End of Day) data for a given symbol from the EODHD API.\"\"\"\n",
        "\n",
        "    base_url = \"https://eodhd.com/api/eod\"\n",
        "    url = f\"{base_url}/{symbol}?api_token={api_token}&fmt=json\"\n",
        "\n",
        "    response = requests.get(url)\n",
        "    response.raise_for_status()  # Raise an exception if the request failed\n",
        "\n",
        "    data = response.json()\n",
        "\n",
        "    # Create DataFrame and filter for the specified number of days\n",
        "    df = pd.DataFrame(data)\n",
        "    df = df.drop(\"volume\", axis=1) # Drop the 'volume' column because the data is not relevant\n",
        "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
        "    df.sort_values(\"date\", ascending=False, inplace=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load.py\n",
        "%%writefile load.py\n",
        "\n",
        "import psycopg2\n",
        "from config import EODHD_API_KEY, SQL_USER, SQL_PASS, SQL_HOST, bond_symbols_dict\n",
        "\n",
        "\"\"\"\n",
        "Helper functions in this .py file:\n",
        "create_connection(),\n",
        "create_database_tables(symbol),\n",
        "load_data_into_database(df, symbol)\n",
        "\"\"\"\n",
        "\n",
        "def create_connection():\n",
        "    \"\"\"Creates a connection to the PostgreSQL database. Helps me use graceful 'with' statements when handling DB connections\"\"\"\n",
        "\n",
        "    try:\n",
        "        my_user = SQL_USER\n",
        "        my_password = SQL_PASS\n",
        "        my_host = SQL_HOST\n",
        "\n",
        "        conn = psycopg2.connect(\n",
        "            database=\"pagila\",\n",
        "            user=my_user,\n",
        "            host=my_host,\n",
        "            password=my_password,\n",
        "            port=5432\n",
        "        )\n",
        "\n",
        "        return conn\n",
        "\n",
        "    except psycopg2.Error as e:\n",
        "        pass # print(f\"Error connecting to database: {e}\")\n",
        "        raise  # Re-raise the error for potential error handling in 'higher-level' calling functions\n",
        "\n",
        "\n",
        "\n",
        "def create_database_tables(symbol):\n",
        "    \"\"\"Creates the required tables in the PostgreSQL database if they don't exist\"\"\"\n",
        "\n",
        "    maturity_class, country = bond_symbols_dict[symbol]\n",
        "    table_name = f\"de10_cdw_{country}_{maturity_class}_gbond\"\n",
        "\n",
        "    # using 'with' statements to help handle connection/cursor objects gracefully\n",
        "    try:\n",
        "      with create_connection() as conn:\n",
        "        with conn.cursor() as cur:\n",
        "\n",
        "          # creates table under \"student\" schema\n",
        "          create_table_sql = f\"\"\"\n",
        "              CREATE TABLE IF NOT EXISTS student.{table_name} (\n",
        "                  date DATE PRIMARY KEY,\n",
        "                  open NUMERIC,\n",
        "                  high NUMERIC,\n",
        "                  low NUMERIC,\n",
        "                  close NUMERIC,\n",
        "                  adjusted_close NUMERIC\n",
        "              )\n",
        "          \"\"\"\n",
        "          cur.execute(create_table_sql)\n",
        "          conn.commit()\n",
        "\n",
        "    except psycopg2.Error as e:\n",
        "        pass # print(f\"Error creating table '{table_name}': {e}\")\n",
        "        raise  # Re-raise the error for potential error handling in 'higher-level' calling functions\n",
        "\n",
        "def load_data_into_database(df, symbol):\n",
        "    \"\"\"Loads data into the specified 'symbol' table in the database.\"\"\"\n",
        "\n",
        "    maturity_class, country = bond_symbols_dict[symbol]\n",
        "    try:\n",
        "      with create_connection() as conn:\n",
        "          create_database_tables(symbol)  # Ensure tables exist before loading\n",
        "          with conn.cursor() as cur:\n",
        "            for _, row in df.iterrows():\n",
        "                cur.execute(f\"\"\"\n",
        "                    INSERT INTO student.de10_cdw_{country}_{maturity_class}_gbond (date, open, high, low, close, adjusted_close)\n",
        "                    VALUES (%s, %s, %s, %s, %s, %s)\n",
        "                \"\"\", (row[\"date\"],\n",
        "                      row[\"open\"],\n",
        "                      row[\"high\"],\n",
        "                      row[\"low\"],\n",
        "                      row[\"close\"],\n",
        "                      row[\"adjusted_close\"])\n",
        "                )\n",
        "                # '%s' place holders in INSERT help with:\n",
        "                # 1)Prevent SQL Injection,\n",
        "                # 2)Type Safety: psycopg2 will automatically convert the Python data types into their corresponding PostgreSQL types\n",
        "            conn.commit()\n",
        "\n",
        "    except psycopg2.Error as error:\n",
        "        pass # print(f\"Database error: {error}\")\n",
        "        raise  # Re-raise the error for potential handling in 'higher-level' calling functions"
      ],
      "metadata": {
        "id": "xLjT50J88pxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a3c1f62-6f74-488f-bb5a-015efb7b83e3"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting load.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# update.py\n",
        "%%writefile update.py\n",
        "\n",
        "import pandas as pd\n",
        "import psycopg2\n",
        "\n",
        "from extract_transform import get_eod_data\n",
        "from load import create_connection, load_data_into_database\n",
        "from config import EODHD_API_KEY, SQL_USER, SQL_PASS, SQL_HOST, bond_symbols_dict\n",
        "\n",
        "def fetch_latest_ingested_date(symbol):\n",
        "    \"\"\"This function exists to help me determine the delta that requires inserting to fulfill the update. It returns the latest data in DB table, or 'None' if table doesn't exist or is empty.\"\"\"\n",
        "    ## I have an ongoing concern that this fn may return 'None' in the event of a connection error or similar - this could mess with the logic of the fn that calls this one and cause an attempt to INSERT already existing data, leading to \"duplicate primary key\" errors from DB\n",
        "\n",
        "    maturity_class, country = bond_symbols_dict[symbol]\n",
        "    table_name = f\"de10_cdw_{country}_{maturity_class}_gbond\"\n",
        "    pass # print(f\"Checking for table: {table_name}\")  # Debug print\n",
        "\n",
        "    try:\n",
        "        with create_connection() as conn:\n",
        "            with conn.cursor() as cur:\n",
        "                # Check if the table exists\n",
        "                cur.execute(\n",
        "                    \"SELECT EXISTS (SELECT 1 FROM information_schema.tables WHERE table_schema = 'student' AND table_name = %s)\",\n",
        "                    (table_name,) #trailing comma ensures arg read as a tuple and not a string\n",
        "                )\n",
        "                table_exists = cur.fetchone()[0]\n",
        "                pass # print(f\"Table exists: {table_exists}\")  # Debug print\n",
        "\n",
        "                if table_exists:\n",
        "                    # Check if the table is empty\n",
        "                    cur.execute(f\"SELECT COUNT(*) FROM student.{table_name};\")\n",
        "                    row_count = cur.fetchone()[0]\n",
        "                    pass # print(f\"Row count: {row_count}\")  # Debug print\n",
        "\n",
        "                    if row_count > 0:\n",
        "                        cur.execute(f\"SELECT MAX(date) FROM student.{table_name};\")\n",
        "                        latest_date = cur.fetchone()[0]\n",
        "                        pass # print(f\"Latest date found: {latest_date}\")  # Debug print\n",
        "                        return latest_date\n",
        "                    else:\n",
        "                        pass # print(\"Table is empty.\")  # Debug print\n",
        "                        return None\n",
        "                else:\n",
        "                    pass # print(\"Table does not exist.\")  # Debug print\n",
        "                    return None\n",
        "    except psycopg2.Error as e:\n",
        "        pass # print(f\"Database error while fetching latest date: {e}\")\n",
        "        raise\n",
        "\n",
        "def update_data(symbol_dict):\n",
        "    \"\"\"Fetches, transforms, and loads the latest data for all specified symbols; if there is no existing data in the corresponding table (or the table does not exist), ALL existing data will be fetched and loaded\"\"\"\n",
        "\n",
        "    # this loop iterates through each bond type, fetches all API data for that bond and filters to keep all rows that are newer than in the current DB table - if there are in fact any new rows, they are loaded into the DB\n",
        "    for symbol, (maturity_class, country) in symbol_dict.items():\n",
        "        # using a 'while' loop below to allow 3 tries at each symbol update, to build-in falut-tolerance in the event that there is an intermittent connection error or similar\n",
        "        retries = 0\n",
        "        while retries < 3:\n",
        "            try:\n",
        "              latest_date_in_db = fetch_latest_ingested_date(symbol)\n",
        "\n",
        "              # Current method fetches all available API data before filtering, only around 30KB per symbol for entire historical feed\n",
        "              all_data_df = get_eod_data(symbol, EODHD_API_KEY)\n",
        "\n",
        "              if latest_date_in_db: #true if there exists a \"latest date\" in table\n",
        "                  # Filter out data already in the database\n",
        "                  latest_date_in_db = pd.Timestamp(latest_date_in_db)\n",
        "                  new_data_df = all_data_df[all_data_df['date'] > latest_date_in_db]\n",
        "              else: #in the event the above if statement is false, ALL data from API loaded.\n",
        "                  new_data_df = all_data_df\n",
        "              # NB must be careful about a fleeting error during fetch_latest_ingested_date(): if latest_date_in_db is returned as 'None', this will cause a load of all API data during update_data() (ie duplicate data) - have tried re-raising the exception in order to force the process to terminate\n",
        "\n",
        "              if not new_data_df.empty:\n",
        "                  load_data_into_database(new_data_df, symbol)\n",
        "                  pass # print(f\"Successfully updated data for {symbol}\")\n",
        "              else:\n",
        "                  pass # print(f\"No new data found for {symbol}\")\n",
        "              break  # Exit the loop after successful update\n",
        "\n",
        "            except Exception as e:\n",
        "              pass # print(f\"Error updating data for {symbol}: {e}\")\n",
        "              retries += 1\n",
        "              if retries >= 3:\n",
        "                  raise  # Re-raise the error for potential error handling in 'higher-level' calling functions\n",
        "    pass # print(\"***API retrieval completed for all symbols***\")"
      ],
      "metadata": {
        "id": "yOQ5_57P_SHv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef3ef83-46dd-4cdc-eb89-0cf2e82db489"
      },
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting update.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile summary_and_moving_averages.py\n",
        "\n",
        "import psycopg2\n",
        "from config import SQL_USER, SQL_PASS, SQL_HOST, bond_symbols_dict\n",
        "from load import create_connection\n",
        "\n",
        "def get_bond_table_names():\n",
        "    try:\n",
        "        with create_connection() as conn:\n",
        "            with conn.cursor() as cur:\n",
        "                # Query for tables in the 'student' schema that start with 'de10_cdw_'\n",
        "                # but EXCLUDE the summary table with AND table_name != 'de10_cdw_bond_summary'\n",
        "                cur.execute(\n",
        "                    \"\"\"\n",
        "                    SELECT table_name\n",
        "                    FROM information_schema.tables\n",
        "                    WHERE table_schema = 'student'\n",
        "                      AND table_name LIKE 'de10_cdw_%'\n",
        "                      AND table_name != 'de10_cdw_bond_summary'\n",
        "                    \"\"\"\n",
        "                )\n",
        "                tables = [row[0] for row in cur.fetchall()]\n",
        "                return tables\n",
        "    except psycopg2.Error as error:\n",
        "        pass # print(f\"Database error: {error}\")\n",
        "        raise\n",
        "\n",
        "def create_summary_moving_averages_table():\n",
        "    try:\n",
        "        bond_table_names = get_bond_table_names()\n",
        "        table_subquery = \" UNION ALL \".join(\n",
        "            [\n",
        "                f\"SELECT '{symbol}' AS symbol, * FROM {f'de10_cdw_{bond_symbols_dict[symbol][1]}_{bond_symbols_dict[symbol][0]}_gbond'}\"\n",
        "                for symbol in bond_symbols_dict.keys()\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        with create_connection() as conn:\n",
        "            with conn.cursor() as cur:\n",
        "                # Drop existing summary table if it exists\n",
        "                cur.execute(\"DROP TABLE IF EXISTS student.de10_cdw_bond_summary;\")\n",
        "                conn.commit()\n",
        "\n",
        "                # Create the table and insert data in a single query\n",
        "                query = f\"\"\"\n",
        "                    CREATE TABLE student.de10_cdw_bond_summary (\n",
        "                        symbol TEXT PRIMARY KEY,\n",
        "                        date DATE,\n",
        "                        num_yield_reports INT,\n",
        "                        latest_yield NUMERIC,\n",
        "                        ma5 NUMERIC,\n",
        "                        diff_ma5 NUMERIC,\n",
        "                        ma20 NUMERIC,\n",
        "                        diff_ma20 NUMERIC,\n",
        "                        ma100 NUMERIC,\n",
        "                        diff_ma100 NUMERIC\n",
        "                    );\n",
        "\n",
        "                    INSERT INTO student.de10_cdw_bond_summary (\n",
        "                        symbol, date, num_yield_reports, latest_yield,\n",
        "                        ma5, diff_ma5, ma20, diff_ma20, ma100, diff_ma100\n",
        "                    )\n",
        "                    SELECT\n",
        "                        symbol,\n",
        "                        MAX(date) AS date,\n",
        "                        COUNT(*) AS num_yield_reports,\n",
        "                        MAX(last_value) AS latest_yield,\n",
        "                        MAX(avg_5) AS ma5,\n",
        "                        MAX(last_value - avg_5) AS diff_ma5,\n",
        "                        MAX(avg_20) AS ma20,\n",
        "                        MAX(last_value - avg_20) AS diff_ma20,\n",
        "                        MAX(avg_100) AS ma100,\n",
        "                        MAX(last_value - avg_100) AS diff_ma100\n",
        "                    FROM (\n",
        "                        SELECT\n",
        "                            symbol,\n",
        "                            date,\n",
        "                            adjusted_close,\n",
        "                            LAST_VALUE(adjusted_close) OVER (PARTITION BY symbol ORDER BY date) AS last_value,\n",
        "                            AVG(adjusted_close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 4 PRECEDING AND CURRENT ROW) AS avg_5,\n",
        "                            AVG(adjusted_close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 19 PRECEDING AND CURRENT ROW) AS avg_20,\n",
        "                            AVG(adjusted_close) OVER (PARTITION BY symbol ORDER BY date ROWS BETWEEN 99 PRECEDING AND CURRENT ROW) AS avg_100\n",
        "                        FROM (\n",
        "                            {table_subquery}\n",
        "                        ) AS all_bond_data\n",
        "                    ) AS subquery_with_window_functions\n",
        "                    GROUP BY symbol;\n",
        "                \"\"\"\n",
        "\n",
        "                cur.execute(query)\n",
        "                conn.commit()\n",
        "\n",
        "    except psycopg2.Error as error:\n",
        "        pass # print(f\"Database error: {error}\")\n",
        "        raise\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2Gfbq7l82eI",
        "outputId": "85799c50-7a69-42f9-96f1-0549ecfbffb7"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting summary_and_moving_averages.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "%%writefile main.py\n",
        "\n",
        "from config import EODHD_API_KEY, SQL_USER, SQL_PASS, SQL_HOST, bond_symbols_dict\n",
        "from update import update_data\n",
        "from summary_and_moving_averages import create_summary_moving_averages_table\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    try:\n",
        "        update_data(bond_symbols_dict)\n",
        "    except Exception as e:\n",
        "        pass # print(f\"Error occurred: {e}\")\n",
        "    else:  # Execute if no exceptions\n",
        "        create_summary_moving_averages_table()\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgqP31Vs-YN5",
        "outputId": "c5e953ec-0969-4a22-da84-aae02ccf3141"
      },
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this code automates the downloading of the generated .py files\n",
        "# NB 1) these downloads frequently seem to stall 2) does not replace existing files with given names, appends and index number instead\n",
        "from google.colab import files\n",
        "\n",
        "file_list = [\"config.py\", \"extract_transform.py\", \"load.py\", \"update.py\", \"summary_and_moving_averages.py\", \"main.py\"]\n",
        "for file_name in file_list:\n",
        "  files.download(file_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "il2kY2GstxtD",
        "outputId": "4453fbd0-ec97-41b0-cfea-437726c5e437"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5bbf1686-3c0e-4983-9ba8-6a7ba8b82248\", \"config.py\", 1067)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7edde307-5b7d-4368-9119-6dd227830d7f\", \"extract_transform.py\", 776)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_273060e8-fdb2-46b7-8681-ce1f40acc0bc\", \"load.py\", 3233)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_44d42b61-8eb7-4861-89d0-20193b0c32d0\", \"update.py\", 4903)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6e2317b6-d573-42c8-9cd3-98746071c367\", \"summary_and_moving_averages.py\", 4101)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_953baa84-7e7f-4e1f-8e73-0d997d95c876\", \"main.py\", 430)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# symbol = \"UK1Y.GBOND\"\n",
        "\n",
        "# latest_date_in_db = fetch_latest_ingested_date(symbol)\n",
        "\n",
        "#             # Fetch all available data\n",
        "# all_data_df = get_eod_data(symbol, api_token)\n",
        "\n",
        "# if latest_date_in_db: #true if there exists a \"latest date\" in table\n",
        "#   # Filter out data already in the database\n",
        "#   new_data_df = all_data_df[all_data_df['date'] > latest_date_in_db]\n",
        "#   if new_data_df is None:\n",
        "#     pass # print(f\"No new data found for {symbol} (new_data_df is None)\")\n",
        "#   pass # print(new_data_df)"
      ],
      "metadata": {
        "id": "WgUTaFHlEM66"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## could store the bond symbols and associated metadata in a JSON file:\n",
        "\n",
        "# # Dictionary with  UK government bond symbols as keys and with list of maturity classes and countries as values\n",
        "# bond_symbols_dict = {\n",
        "#     \"UK1Y.GBOND\": [\"1Y\", \"UK\"],\n",
        "#     \"UK2Y.GBOND\": [\"2Y\", \"UK\"],\n",
        "#     \"UK3Y.GBOND\": [\"3Y\", \"UK\"],\n",
        "#     \"UK5Y.GBOND\": [\"5Y\", \"UK\"],\n",
        "#     \"UK10Y.GBOND\": [\"10Y\", \"UK\"],\n",
        "#     \"UK30Y.GBOND\": [\"30Y\", \"UK\"]\n",
        "# }\n",
        "\n",
        "# bond_symbols.split()\n",
        "# using this code to access JSON where needed\n",
        "# bond_symbols = json.load(open('bonds.json'))"
      ],
      "metadata": {
        "id": "G2RLJzo6J0Ci"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# symbol = \"UK1Y.GBOND\"\n",
        "# GBOND_UK_1Y_df = get_eod_data(symbol, api_token)\n",
        "\n",
        "# example_df = GBOND_UK_3Y_10days_df\n",
        "# pass # print(\"GBOND_UK_1Y\\n\", example_df)\n",
        "\n",
        "# # conn=create_connection()\n",
        "# country = \"uk\"\n",
        "# maturity_class = \"1y\"\n",
        "# table_name = f\"de10_cdw_{country}_{maturity_class}_gbond\"\n",
        "# pass # print(fetch_latest_ingested_date(symbol))\n",
        "# load_data_into_database(example_df,symbol)"
      ],
      "metadata": {
        "id": "IE8b5d8MO3LJ"
      },
      "execution_count": 189,
      "outputs": []
    }
  ]
}